{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_artist_info(artist_name, page):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    headers = {\"Authorization\": \"Bearer \" + config.api_key}\n",
    "    search_url = base_url + \"/search\"\n",
    "    params = {\"q\": artist_name, \"per_page\": 10, \"page\": page}\n",
    "    response = requests.get(search_url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}- {response.text}\")\n",
    "        return None\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reques_song_url(artist_name, song_cap):\n",
    "    \n",
    "    page = 1\n",
    "    songs = []\n",
    "    while True:\n",
    "        response = request_artist_info(artist_name, page)\n",
    "        if response is None:\n",
    "            break\n",
    "        json_data = response.json()\n",
    "\n",
    "        if \"response\" not in json_data or \"hits\" not in json_data[\"response\"]:\n",
    "            print(\"Error: 'response' or 'hits' key not found in the response data\")\n",
    "            break\n",
    "        song_info = []\n",
    "\n",
    "        for hit in json_data[\"response\"][\"hits\"]:\n",
    "            if artist_name.lower() in hit[\"result\"][\"primary_artist\"][\"name\"].lower():\n",
    "                song_info.append(hit)\n",
    "        \n",
    "        for song in song_info:\n",
    "            if len(songs) < song_cap:\n",
    "                url = song[\"result\"][\"url\"]\n",
    "                songs.append(url)\n",
    "        if len(songs) == song_cap:\n",
    "            break\n",
    "        else:\n",
    "            page += 1\n",
    "    print(\"Found {} songs by {}\".format(len(songs), artist_name))\n",
    "\n",
    "    return songs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_song_lyrics(url):\n",
    "    \n",
    "    # Make an HTTP GET request to the provided song URL\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # Parse the page content using BeautifulSoup\n",
    "    html = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Find all <div> elements with the 'data-lyrics-container' attribute which contains the lyrics\n",
    "    lyrics_divs = html.find_all('div', attrs={'data-lyrics-container': 'true'})\n",
    "    \n",
    "    # If no lyrics are found, print an error message and return an empty string\n",
    "    if not lyrics_divs:\n",
    "        print(f\"Could not find lyrics for {url}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Extract the text from each lyrics <div> and join them with a newline separator\n",
    "    lyrics = '\\n'.join([div.get_text(separator=\"\\n\") for div in lyrics_divs])\n",
    "    \n",
    "    # Remove unwanted identifiers like [Chorus], [Verse], etc. using regular expressions\n",
    "    lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', lyrics)\n",
    "    \n",
    "    # Remove empty lines from the lyrics\n",
    "    lyrics = os.linesep.join([s for s in lyrics.splitlines() if s])\n",
    "    \n",
    "    # Return the cleaned lyrics\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_lyrics_to_csv(artist_name, song_count):\n",
    "    \"\"\"\n",
    "    Writes the lyrics of songs by a given artist to a CSV file, with each line of the lyrics as a separate row.\n",
    "    \n",
    "    Parameters:\n",
    "    - artist_name: The name of the artist.\n",
    "    - song_count: The number of songs to retrieve and write to the file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the 'lyrics' directory if it doesn't exist\n",
    "    if not os.path.exists('lyrics'):\n",
    "        os.makedirs('lyrics')\n",
    "\n",
    "    # Generate the file path for the CSV file, replacing spaces with underscores\n",
    "    file_path = 'lyrics/' + artist_name.lower().replace(' ', '_') + '.csv'\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Define the column names for the CSV file\n",
    "        fieldnames = ['Song', 'Lyrics']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Retrieve song URLs from Genius API\n",
    "        urls = reques_song_url(artist_name, song_count)\n",
    "        \n",
    "        # Loop through each song URL\n",
    "        for url in urls:\n",
    "            # Extract song name from the URL by replacing '-' with spaces and title-casing it\n",
    "            song_name = url.split('/')[-1].replace('-', ' ').title()\n",
    "            \n",
    "            # Dynamically remove the artist's name from the song title\n",
    "            song_name = song_name.replace(artist_name.title() + ' ', '').replace(' Lyrics', '')  # Clean song name\n",
    "            \n",
    "            # Scrape the lyrics for the current song\n",
    "            lyrics = scrape_song_lyrics(url)\n",
    "            \n",
    "            # Only write to the CSV file if lyrics are found\n",
    "            if lyrics:\n",
    "                # Split lyrics into lines and write each line to a new row\n",
    "                lyrics_text = \"\\n\".join(lyrics.splitlines())\n",
    "                writer.writerow({\"Song\": song_name, \"Lyrics\": lyrics_text})\n",
    "                # for line in lyrics.splitlines():\n",
    "                #     writer.writerow({'Song': song_name, 'Lyrics': line})\n",
    "    \n",
    "    # Print a message indicating success\n",
    "    print(f'Lyrics written to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 songs by Sabrina Carpenter\n",
      "Could not find lyrics for https://genius.com/Sabrina-carpenter-espresso-on-vacation-version-lyrics\n",
      "Lyrics written to lyrics/sabrina_carpenter.csv\n"
     ]
    }
   ],
   "source": [
    "write_lyrics_to_csv(\"Sabrina Carpenter\", 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
